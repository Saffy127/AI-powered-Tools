{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWkWuVTSXkJ/I57P6fC5GD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saffy127/AI-powered-Tools/blob/main/langchainWork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDsRgPGg1pEy",
        "outputId": "f45b7c32-d795-4a05-e618-09d727d94b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.1.7-py3-none-any.whl (815 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.9/815.9 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.20 (from langchain)\n",
            "  Downloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.22 (from langchain)\n",
            "  Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, jsonpatch, httpcore, langsmith, httpx, dataclasses-json, openai, langchain-core, langchain-community, langchain\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.4 h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.7 langchain-community-0.0.20 langchain-core-0.1.23 langsmith-0.0.87 marshmallow-3.20.2 mypy-extensions-1.0.0 openai-1.12.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai tiktoken cohere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD52i9vY1yrW",
        "outputId": "d2959c30-f97b-4265-cf9a-b99dc28c697b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.0.6-py3-none-any.whl (29 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cohere\n",
            "  Downloading cohere-4.47-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.2,>=0.1.16 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.23)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.25.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.12.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.3)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
            "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib_metadata<7.0,>=6.0 (from cohere)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.0.88,>=0.0.87 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain_openai) (0.0.87)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain_openai) (2.6.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain_openai) (8.2.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.26.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain_openai) (1.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.3)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain_openai) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain_openai) (2.16.2)\n",
            "Installing collected packages: importlib_metadata, fastavro, backoff, tiktoken, cohere, langchain_openai\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib-metadata 7.0.1\n",
            "    Uninstalling importlib-metadata-7.0.1:\n",
            "      Successfully uninstalled importlib-metadata-7.0.1\n",
            "Successfully installed backoff-2.2.1 cohere-4.47 fastavro-1.9.4 importlib_metadata-6.11.0 langchain_openai-0.0.6 tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "5UPzf-6618x5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI()"
      ],
      "metadata": {
        "id": "wjQQq3D22Cic"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"what is docker and how is it useful for deployment?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q5PY1fI2Eu-",
        "outputId": "c1e84495-646b-4ede-8972-f2390055bfd1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Docker is an open-source platform that allows you to automate the deployment, scaling, and management of applications using containerization. Containers are lightweight, isolated environments that contain all the dependencies needed to run an application, including the code, runtime, libraries, and system tools.\\n\\nHere are some ways Docker is useful for deployment:\\n\\n1. Portability: Docker containers encapsulate the application and its dependencies, making them highly portable across different environments. This ensures consistency in deployment, regardless of the underlying infrastructure.\\n\\n2. Scalability: Docker enables you to easily scale your application horizontally by running multiple containers on a single host or across multiple hosts. This allows you to handle increased traffic or workload efficiently.\\n\\n3. Efficiency: Docker's containerization approach eliminates the need for running a separate virtual machine for each application, resulting in reduced resource consumption and improved efficiency.\\n\\n4. Dependency Management: Docker allows you to package all the dependencies required for your application within the container. This eliminates conflicts between different versions of libraries or system tools, making deployment more reliable.\\n\\n5. Continuous Deployment: Docker integrates well with continuous integration and continuous deployment (CI/CD) pipelines. It enables developers to package their applications into containers and deploy them consistently across different environments, including development, testing, and production.\\n\\n6. Isolation and Security: Docker containers provide isolation between applications and the underlying host system, ensuring that any issues in one container don't affect others. Additionally, Docker's built-in security features, like user namespaces and resource limitations, enhance the overall security of deployed applications.\\n\\nOverall, Docker simplifies the deployment process, improves application portability, scalability, efficiency, and enhances the overall reliability and security of your deployment environment.\")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an English-French translator that return whatever the user says in French.\"),\n",
        "    (\"user\", \"{input}\")\n",
        "])\n",
        "\n",
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "xjaq-2x_2XMB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\n",
        "    \"input\": \"i enjoy going to heavy metal concerts\"\n",
        "  })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j6zquaU3UfI",
        "outputId": "5da3ee89-ff16-4122-e444-f8f16259c9c4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"j'apprécie d'aller à des concerts de heavy metal\")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add output parser to the chain\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "output_parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "5Z-8gE0C3kfr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm | output_parser"
      ],
      "metadata": {
        "id": "TVrExxjf4lVp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"input\": \"I can't wait to go see The Devil Wears Prada and Fit for a King live!\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c41JA_Iw4qc1",
        "outputId": "21a7e965-cf82-48d4-ceb5-27fc4feac324"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Je suis impatient d'aller voir The Devil Wears Prada et Fit for a King en direct !\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now trying to make a RAG chain.\n",
        "# retrieval chain\n",
        "!pip install beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdVByMo-5EPo",
        "outputId": "83add19d-e82d-4c39-d143-e79097424049"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using Vector store\n",
        "! pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obTOwmos68cm",
        "outputId": "cde63757-f3f7-4b7e-bede-eaf8ba0e41c9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/LangChain\")\n",
        "\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "ohoualcg7C7x"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzO4Opd-7bx-",
        "outputId": "8376eb77-37cd-4838-dd3f-e10524f6eac9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='\\n\\n\\n\\nLangChain - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\\n\\n\\n\\n\\n\\nLanguages\\n\\nLanguage links are at the top of the page.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\n Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1History\\n\\n\\n\\n\\n\\n\\n\\n2Capabilities\\n\\n\\n\\n\\n\\n\\n\\n3LangChain tools\\n\\n\\n\\n\\n\\n\\n\\n4References\\n\\n\\n\\n\\n\\n\\n\\n5External links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n6 languages\\n\\n\\n\\n\\nŸÅÿßÿ±ÿ≥€åÌïúÍµ≠Ïñ¥‡§π‡§ø‡§®‡•ç‡§¶‡•ÄÊó•Êú¨Ë™ûPortugu√™s‰∏≠Êñá\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR codeWikidata item\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\nLanguage model application development framework\\nLangChainDeveloper(s)Harrison ChaseInitial releaseOctober 2022Stable release0.1.1[1]\\n   / 16 January 2024; 31 days ago\\xa0(16 January 2024)\\nRepositorygithub.com/langchain-ai/langchainWritten inPython and JavaScriptTypeSoftware framework for large language model application developmentLicenseMIT LicenseWebsiteLangChain.com\\nLangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\n\\n\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. The project quickly garnered popularity,[3] with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project\\'s Discord server, many YouTube tutorials, and meetups in San Francisco and London. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[4][5]\\nIn October 2023 LangChain introduced LangServe, a deployment tool designed to facilitate the transition from LCEL (LangChain Expression Language) prototypes to production-ready applications.[6]\\n\\nCapabilities[edit]\\nLangChain\\'s developers highlight the framework\\'s applicability to use-cases including chatbots,[7] retrieval-augmented generation,[8]  document summarization,[9] and synthetic data generation.[10]\\nAs of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \"todo\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database[11] to store and retrieve vector embeddings; Weaviate vector database[12] to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[13] As of April 2023, it can read from more than 50 document types and data sources.[14]\\n\\nLangChain tools[edit]\\n\\n\\n\\n\\nTool name\\n\\nAccount required?\\n\\nAPI key required?\\n\\nLicencing\\n\\nDescription\\n\\nFeatures\\n\\nDocumentation URL\\n\\n\\nAlpha  Vantage\\n\\nNo\\n\\nYes\\n\\nProprietary\\n\\nProvides  financial market data and analytics\\n\\nFinancial  data, analytics\\n\\nhttps://python.langchain.com/docs/integrations/tools/alpha_vantage\\n\\n\\nApify\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nWeb  scraping and automation platform\\n\\nWeb  scraping, automation\\n\\nhttps://python.langchain.com/docs/integrations/tools/apify\\n\\n\\nArXiv\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nAccess  to scientific papers and research\\n\\nScientific  papers, research\\n\\nhttps://python.langchain.com/docs/integrations/tools/arxiv\\n\\n\\nAWS  Lambda\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nServerless  computing service\\n\\nServerless  computing\\n\\nhttps://python.langchain.com/docs/integrations/tools/awslambda\\n\\n\\nBash\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nAccess to the shell environment\\n\\nShell  environment access\\n\\nhttps://python.langchain.com/docs/integrations/tools/bash\\n\\n\\nBearly  Code Interpreter\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nRemote  execution of Python code\\n\\nPython  code execution\\n\\nhttps://python.langchain.com/docs/integrations/tools/bearly\\n\\n\\nBing  Search\\n\\nNo\\n\\nYes\\n\\nProprietary\\n\\nSearch  engine powered by Microsoft Bing\\n\\nSearch  engine\\n\\nhttps://python.langchain.com/docs/integrations/tools/bing_search\\n\\n\\nBrave  Search\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nPrivacy-focused  search engine\\n\\nPrivacy-focused  search\\n\\nhttps://python.langchain.com/docs/integrations/tools/brave_search\\n\\n\\nChatGPT  Plugins\\n\\nNo\\n\\nYes\\n\\nProprietary\\n\\nPlugins  for ChatGPT language model\\n\\nChatGPT  plugins\\n\\nhttps://python.langchain.com/docs/integrations/tools/chatgpt_plugins\\n\\n\\nConnery\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nAction  Tool Tool for performing actions using the Connery API\\n\\nAPI  actions\\n\\nhttps://python.langchain.com/docs/integrations/tools/connery\\n\\n\\nDall-E  Image Generator\\n\\nNo\\n\\nYes\\n\\nProprietary\\n\\nText-to-image  generation using OpenAI\\'s DALL-E model\\n\\nText-to-image  generation\\n\\nhttps://python.langchain.com/docs/integrations/tools/dalle_image_generator\\n\\n\\nDataForSEO\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nSEO  data and analytics platform\\n\\nSEO  data, analytics\\n\\nhttps://python.langchain.com/docs/integrations/tools/dataforseo\\n\\n\\nDuckDuckGo  Search\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nPrivacy-focused  search engine\\n\\nSearch  engine\\n\\nhttps://python.langchain.com/docs/integrations/tools/ddg\\n\\n\\nE2B  Data Analysis\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nSandbox  environment for running Python code for data analysis\\n\\nData  analysis environment\\n\\nhttps://python.langchain.com/docs/integrations/tools/e2b_data_analysis\\n\\n\\nEden  AI\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nSuite  of AI tools and APIs\\n\\nAI  tools, APIs\\n\\nhttps://python.langchain.com/docs/integrations/tools/edenai_tools\\n\\n\\nEleven  Labs Text2Speech\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nText-to-speech  API by Eleven Labs\\n\\nText-to-speech\\n\\nhttps://python.langchain.com/docs/integrations/tools/eleven_labs_tts\\n\\n\\nExa  Search\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nSearch  engine\\n\\nSearch  engine access\\n\\nhttps://python.langchain.com/docs/integrations/tools/exa_search\\n\\n\\nFile  System\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nTools  for interacting with the local file system\\n\\nFile  system interaction\\n\\nhttps://python.langchain.com/docs/integrations/tools/filesystem\\n\\n\\nGolden  Query\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nNatural  language APIs for querying various services\\n\\nNatural  language queries\\n\\nhttps://python.langchain.com/docs/integrations/tools/golden_query\\n\\n\\nGoogle  Cloud Text-to-Speech\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nText-to-speech  API by Google Cloud\\n\\nText-to-speech\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_cloud_texttospeech\\n\\n\\nGoogle  Drive\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nAccess  and manage files on Google Drive\\n\\nGoogle  Drive access\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_drive\\n\\n\\nGoogle  Finance\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nAccess  financial data from Google Finance\\n\\nFinancial  data\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_finance\\n\\n\\nGoogle  Jobs\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nSearch  for job listings using Google Jobs API\\n\\nJob  search\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_jobs\\n\\n\\nGoogle  Lens\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nVisual  search and recognition tool by Google\\n\\nVisual  search, recognition\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_lens\\n\\n\\nGoogle  Places\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nAccess  to Google Places API for location-based services\\n\\nLocation-based  services\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_places\\n\\n\\nGoogle  Scholar\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nSearch  for scholarly articles using Google Scholar API\\n\\nScholarly  article search\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_scholar\\n\\n\\nGoogle  Search\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nSearch  engine powered by Google\\n\\nSearch  engine\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_search\\n\\n\\nGoogle  Serper\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nSearch  engine results page (SERP) scraping tool\\n\\nSERP  scraping\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_serper\\n\\n\\nGoogle  Trends\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nAccess  to Google Trends data\\n\\nTrend  data\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_trends\\n\\n\\nGradio\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nLibrary  for creating UIs for machine learning models\\n\\nMachine  learning UIs\\n\\nhttps://python.langchain.com/docs/integrations/tools/gradio_tools\\n\\n\\nGraphQL\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nQuery  language for APIs\\n\\nAPI  queries\\n\\nhttps://python.langchain.com/docs/integrations/tools/graphql\\n\\n\\nHuggingFace  Hub\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nTools  for working with Hugging Face models and datasets\\n\\nHugging  Face models, datasets\\n\\nhttps://python.langchain.com/docs/integrations/tools/huggingface_tools\\n\\n\\nHuman  as a tool\\n\\nNo\\n\\nNo\\n\\nN/A\\n\\nUse  human input as a tool for AI\\n\\nHuman  input\\n\\nhttps://python.langchain.com/docs/integrations/tools/human_tools\\n\\n\\nIFTTT  WebHooks\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nConnect  and automate various web services\\n\\nWeb  service automation\\n\\nhttps://python.langchain.com/docs/integrations/tools/ifttt\\n\\n\\nIonic  Shopping\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nTool  for shopping using the Ionic API\\n\\nShopping\\n\\nhttps://python.langchain.com/docs/integrations/tools/ionic_shopping\\n\\n\\nLemon  Agent\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nTool  for interacting with the Lemon AI platform\\n\\nLemon  AI interaction\\n\\nhttps://python.langchain.com/docs/integrations/tools/lemonai\\n\\n\\nMemorize\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nTool  for memorizing information using unsupervised learning\\n\\nMemorization\\n\\nhttps://python.langchain.com/docs/integrations/tools/memorize\\n\\n\\nNuclia\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nUnderstanding  Tool for indexing unstructured data using Nuclia\\n\\nData  indexing\\n\\nhttps://python.langchain.com/docs/integrations/tools/nuclia\\n\\n\\nOpenWeatherMap\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nAccess  to weather data using OpenWeatherMap API\\n\\nWeather  data\\n\\nhttps://python.langchain.com/docs/integrations/tools/openweathermap\\n\\n\\nPolygon  Stock Market API\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nAccess  to stock market data using Polygon API\\n\\nStock  market data\\n\\nhttps://python.langchain.com/docs/integrations/tools/polygon\\n\\n\\nPubMed\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nAccess  to biomedical literature using PubMed API\\n\\nBiomedical  literature\\n\\nhttps://python.langchain.com/docs/integrations/tools/pubmed\\n\\n\\nPython  REPL\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nInteractive  Python shell\\n\\nPython  shell\\n\\nhttps://python.langchain.com/docs/integrations/tools/python\\n\\n\\nReddit Search\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nSearch  for content on Reddit\\n\\nReddit  search\\n\\nhttps://python.langchain.com/docs/integrations/tools/reddit_search\\n\\n\\nRequests\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nHTTP  library for making requests\\n\\nHTTP  requests\\n\\nhttps://python.langchain.com/docs/integrations/tools/requests\\n\\n\\nSceneXplain\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nTool  for explaining the predictions of machine learning models\\n\\nModel  explanations\\n\\nhttps://python.langchain.com/docs/integrations/tools/sceneXplain\\n\\n\\nSearch\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nCollection  of tools for searching and querying various services\\n\\nSearch  tools\\n\\nhttps://python.langchain.com/docs/integrations/tools/search_tools\\n\\n\\nSearchApi\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nTool  for searching and querying various APIs\\n\\nAPI  search tools\\n\\nhttps://python.langchain.com/docs/integrations/tools/searchapi\\n\\n\\nSearxNG\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nSearch  Privacy-focused metasearch engine\\n\\nPrivacy-focused  search\\n\\nhttps://python.langchain.com/docs/integrations/tools/searx_search\\n\\n\\nSemantic  Scholar API\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\ntool  Access to academic papers using the Semantic Scholar API\\n\\nAcademic  paper search\\n\\nhttps://python.langchain.com/docs/integrations/tools/semanticscholar\\n\\n\\nSerpAPI\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nSearch  engine results page (SERP) scraping tool\\n\\nSERP  scraping\\n\\nhttps://python.langchain.com/docs/integrations/tools/serpapi\\n\\n\\nStackExchange\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nAccess  to the Stack Exchange network\\n\\nStack  Exchange access\\n\\nhttps://python.langchain.com/docs/integrations/tools/stackexchange\\n\\n\\nTavily  Search\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nSearch  engine for finding answers to questions\\n\\nQuestion  answering\\n\\nhttps://python.langchain.com/docs/integrations/tools/tavily_search\\n\\n\\nTwilio\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nCommunication  APIs for SMS, voice, and video\\n\\nCommunication  APIs\\n\\nhttps://python.langchain.com/docs/integrations/tools/twilio\\n\\n\\nWikidata\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nAccess  to structured data from Wikidata\\n\\nStructured  data access\\n\\nhttps://python.langchain.com/docs/integrations/tools/wikidata\\n\\n\\nWikipedia\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nAccess  to articles and information from Wikipedia\\n\\nWikipedia  access\\n\\nhttps://python.langchain.com/docs/integrations/tools/wikipedia\\n\\n\\nWolfram  Alpha\\n\\nNo\\n\\nYes\\n\\nProprietary\\n\\nComputational  knowledge engine\\n\\nComputational  knowledge\\n\\nhttps://python.langchain.com/docs/integrations/tools/wolfram_alpha\\n\\n\\nYahoo  Finance News\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nAccess  to financial news using Yahoo Finance API\\n\\nFinancial  news\\n\\nhttps://python.langchain.com/docs/integrations/tools/yahoo_finance_news\\n\\n\\nYoutube\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nAccess  to YouTube data and functionality\\n\\nYouTube  access\\n\\nhttps://python.langchain.com/docs/integrations/tools/youtube\\n\\n\\nZapier  Natural Language Actions\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nIntegration  platform for automating workflows\\n\\nWorkflow  automation\\n\\nhttps://python.langchain.com/docs/integrations/tools/zapier\\n\\n\\n\\nReferences[edit]\\n\\n\\n^ \"Release 0.1.1\". 16 January 2024. Retrieved 19 January 2024.\\n\\n^ Buniatyan, Davit (2023). \"Code Understanding Using LangChain\". Activeloop.\\n\\n^ Auffarth, Ben (2023). Generative AI with LangChain. Birmingham: Packt Publishing. p.\\xa083. ISBN\\xa09781835083468.\\n\\n^ Palazzolo, Stephanie (2023-04-13). \"AI startup LangChain taps Sequoia to lead funding round at a valuation of at least $200 million\". Business Insider. Archived from the original on 2023-04-18. Retrieved 2023-04-18.\\n\\n^ Griffith, Erin; Metz, Cade (2023-03-14). \"\\'Let 1,000 Flowers Bloom\\': A.I. Funding Frenzy Escalates\". The New York Times. ISSN\\xa00362-4331. Archived from the original on 2023-04-18. Retrieved 2023-04-18.\\n\\n^ \"Introducing LangServe, the best way to deploy your LangChains\". LangChain Blog. 2023-10-12. Retrieved 2023-10-17.\\n\\n^ \"Chatbots | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain\". python.langchain.com. Retrieved 2023-11-26.\\n\\n^ \"Retrieval-augmented generation (RAG) | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain\". python.langchain.com. Retrieved 2023-11-26.\\n\\n^ \"Summarization | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain\". python.langchain.com. Retrieved 2023-11-26.\\n\\n^ \"Synthetic data generation | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain\". python.langchain.com. Retrieved 2023-11-26.\\n\\n^ \"Milvus ‚Äî LangChain\". python.langchain.com. Retrieved 2023-10-29.\\n\\n^ \"Weaviate\". python.langchain.com. Retrieved 2024-01-17.\\n\\n^ Hug, Daniel Patrick (2023-03-08). \"Hierarchical topic tree of LangChain\\'s integrations\" (PDF). GitHub. Archived from the original on 2023-04-29. Retrieved 2023-04-18.\\n\\n^ \"Document Loaders ‚Äî LangChain 0.0.142\". python.langchain.com. Archived from the original on 2023-04-18. Retrieved 2023-04-18.\\n\\n\\nExternal links[edit]\\n\\n\\n\\nWikidata has data related to LangChain\\n\\nOfficial website\\nDiscord server support hub\\nvteOpenAIProducts\\nChatGPT\\nin education\\nDALL-E\\nGitHub Copilot\\nOpenAI Five\\nSora\\nWhisper\\nFoundation models\\nOpenAI Codex\\nGenerative pre-trained transformer\\nGPT-1\\nGPT-2\\nGPT-3\\nGPT-4\\nPeopleCEOs\\nSam Altman\\nremoval\\nMira Murati\\nEmmett Shear\\nBoard of directorsCurrent\\nBret Taylor\\nLarry Summers\\nAdam D\\'Angelo\\nFormer\\nGreg Brockman (2017‚Äì2023)\\nReid Hoffman (2019‚Äì2023)\\nWill Hurd (2021‚Äì2023)\\nHolden Karnofsky (2017‚Äì2021)\\nElon Musk (2015‚Äì2018)\\nIlya Sutskever (2017‚Äì2023)\\nHelen Toner (2021‚Äì2023)\\nShivon Zilis (2019‚Äì2023)\\nRelated\\nAI Dungeon\\nAuto-GPT\\n\"Deep Learning\"\\nLangChain\\nMicrosoft Copilot\\nMicrosoft Bing\\n\\n Category\\n Commons\\n\\nvteDifferentiable computingGeneral\\nDifferentiable programming\\nInformation geometry\\nStatistical manifold\\nAutomatic differentiation\\nNeuromorphic engineering\\nPattern recognition\\nTensor calculus\\nComputational learning theory\\nInductive bias\\nConcepts\\nGradient descent\\nSGD\\nClustering\\nRegression\\nOverfitting\\nHallucination\\nAdversary\\nAttention\\nConvolution\\nLoss functions\\nBackpropagation\\nBatchnorm\\nActivation\\nSoftmax\\nSigmoid\\nRectifier\\nRegularization\\nDatasets\\nAugmentation\\nDiffusion\\nAutoregression\\nApplications\\nMachine learning\\nIn-context learning\\nArtificial neural network\\nDeep learning\\nScientific computing\\nArtificial Intelligence\\nLanguage model\\nLarge language model\\nHardware\\nIPU\\nTPU\\nVPU\\nMemristor\\nSpiNNaker\\nSoftware libraries\\nTensorFlow\\nPyTorch\\nKeras\\nTheano\\nJAX\\nFlux.jl\\nMindSpore\\nImplementationsAudio‚Äìvisual\\nAlexNet\\nWaveNet\\nHuman image synthesis\\nHWR\\nOCR\\nSpeech synthesis\\nSpeech recognition\\nFacial recognition\\nAlphaFold\\nDALL-E\\nMidjourney\\nStable Diffusion\\nWhisper\\nVerbal\\nWord2vec\\nSeq2seq\\nBERT\\nGemini\\nLaMDA\\nBard\\nNMT\\nProject Debater\\nIBM Watson\\nIBM Watsonx\\nGranite\\nGPT-1\\nGPT-2\\nGPT-3\\nGPT-4\\nChatGPT\\nGPT-J\\nChinchilla AI\\nPaLM\\nBLOOM\\nLLaMA\\nPanGu-Œ£\\nDecisional\\nAlphaGo\\nAlphaZero\\nQ-learning\\nSARSA\\nOpenAI Five\\nSelf-driving car\\nMuZero\\nAction selection\\nAuto-GPT\\nRobot control\\nPeople\\nYoshua Bengio\\nAlex Graves\\nIan Goodfellow\\nStephen Grossberg\\nDemis Hassabis\\nGeoffrey Hinton\\nYann LeCun\\nFei-Fei Li\\nAndrew Ng\\nJ√ºrgen Schmidhuber\\nDavid Silver\\nIlya Sutskever\\nOrganizations\\nAnthropic\\nEleutherAI\\nGoogle DeepMind\\nHugging Face\\nOpenAI\\nMeta AI\\nMila\\nMIT CSAIL\\nHuawei\\nArchitectures\\nNeural Turing machine\\nDifferentiable neural computer\\nTransformer\\nRecurrent neural network (RNN)\\nLong short-term memory (LSTM)\\nGated recurrent unit (GRU)\\nEcho state network\\nMultilayer perceptron (MLP)\\nConvolutional neural network\\nResidual neural network\\nMamba\\nAutoencoder\\nVariational autoencoder (VAE)\\nGenerative adversarial network (GAN)\\nGraph neural network\\n\\n Portals\\nComputer programming\\nTechnology\\n Categories\\nArtificial neural networks\\nMachine learning\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=LangChain&oldid=1207691404\"\\nCategories: Artificial intelligenceLarge language modelsSoftware frameworks2022 softwareHidden categories: Articles with short descriptionShort description matches WikidataPages using Sister project links with hidden wikidata\\n\\n\\n\\n\\n\\n\\n This page was last edited on 15 February 2024, at 12:57\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike License 4.0;\\nadditional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia¬Æ is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle limited content width\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://en.wikipedia.org/wiki/LangChain', 'title': 'LangChain - Wikipedia', 'language': 'en'})]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Embeddings model to add to vector store\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "ClAcFgzB7cv3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter()\n",
        "documents = text_splitter.split_documents(docs)\n",
        "#Vector Store\n",
        "vectorstore = FAISS.from_documents(documents, embeddings)"
      ],
      "metadata": {
        "id": "g2S1VZsB70dl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp8NjsQ88adv",
        "outputId": "43a9a98d-7a5b-4d6e-f35d-7eeeac356ff3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"LangChain - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\\n\\n\\n\\n\\n\\nLanguages\\n\\nLanguage links are at the top of the page.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\n Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1History\\n\\n\\n\\n\\n\\n\\n\\n2Capabilities\\n\\n\\n\\n\\n\\n\\n\\n3LangChain tools\\n\\n\\n\\n\\n\\n\\n\\n4References\\n\\n\\n\\n\\n\\n\\n\\n5External links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n6 languages\\n\\n\\n\\n\\nŸÅÿßÿ±ÿ≥€åÌïúÍµ≠Ïñ¥‡§π‡§ø‡§®‡•ç‡§¶‡•ÄÊó•Êú¨Ë™ûPortugu√™s‰∏≠Êñá\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR codeWikidata item\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\nLanguage model application development framework\\nLangChainDeveloper(s)Harrison ChaseInitial releaseOctober 2022Stable release0.1.1[1]\\n   / 16 January 2024; 31 days ago\\xa0(16 January 2024)\\nRepositorygithub.com/langchain-ai/langchainWritten inPython and JavaScriptTypeSoftware framework for large language model application developmentLicenseMIT LicenseWebsiteLangChain.com\\nLangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\n\\n\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. The project quickly garnered popularity,[3] with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project's Discord server, many YouTube tutorials, and meetups in San Francisco and London. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[4][5]\\nIn October 2023 LangChain introduced LangServe, a deployment tool designed to facilitate the transition from LCEL (LangChain Expression Language) prototypes to production-ready applications.[6]\", metadata={'source': 'https://en.wikipedia.org/wiki/LangChain', 'title': 'LangChain - Wikipedia', 'language': 'en'}),\n",
              " Document(page_content='Capabilities[edit]\\nLangChain\\'s developers highlight the framework\\'s applicability to use-cases including chatbots,[7] retrieval-augmented generation,[8]  document summarization,[9] and synthetic data generation.[10]\\nAs of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \"todo\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database[11] to store and retrieve vector embeddings; Weaviate vector database[12] to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[13] As of April 2023, it can read from more than 50 document types and data sources.[14]\\n\\nLangChain tools[edit]\\n\\n\\n\\n\\nTool name\\n\\nAccount required?\\n\\nAPI key required?\\n\\nLicencing\\n\\nDescription\\n\\nFeatures\\n\\nDocumentation URL\\n\\n\\nAlpha  Vantage\\n\\nNo\\n\\nYes\\n\\nProprietary\\n\\nProvides  financial market data and analytics\\n\\nFinancial  data, analytics\\n\\nhttps://python.langchain.com/docs/integrations/tools/alpha_vantage\\n\\n\\nApify\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nWeb  scraping and automation platform\\n\\nWeb  scraping, automation\\n\\nhttps://python.langchain.com/docs/integrations/tools/apify\\n\\n\\nArXiv\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nAccess  to scientific papers and research\\n\\nScientific  papers, research\\n\\nhttps://python.langchain.com/docs/integrations/tools/arxiv\\n\\n\\nAWS  Lambda\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nServerless  computing service\\n\\nServerless  computing\\n\\nhttps://python.langchain.com/docs/integrations/tools/awslambda\\n\\n\\nBash\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nAccess to the shell environment\\n\\nShell  environment access\\n\\nhttps://python.langchain.com/docs/integrations/tools/bash\\n\\n\\nBearly  Code Interpreter\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nRemote  execution of Python code\\n\\nPython  code execution\\n\\nhttps://python.langchain.com/docs/integrations/tools/bearly\\n\\n\\nBing  Search\\n\\nNo\\n\\nYes\\n\\nProprietary\\n\\nSearch  engine powered by Microsoft Bing\\n\\nSearch  engine\\n\\nhttps://python.langchain.com/docs/integrations/tools/bing_search\\n\\n\\nBrave  Search\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nPrivacy-focused  search engine\\n\\nPrivacy-focused  search\\n\\nhttps://python.langchain.com/docs/integrations/tools/brave_search\\n\\n\\nChatGPT  Plugins\\n\\nNo\\n\\nYes\\n\\nProprietary\\n\\nPlugins  for ChatGPT language model\\n\\nChatGPT  plugins\\n\\nhttps://python.langchain.com/docs/integrations/tools/chatgpt_plugins\\n\\n\\nConnery\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nAction  Tool Tool for performing actions using the Connery API\\n\\nAPI  actions\\n\\nhttps://python.langchain.com/docs/integrations/tools/connery\\n\\n\\nDall-E  Image Generator\\n\\nNo\\n\\nYes\\n\\nProprietary\\n\\nText-to-image  generation using OpenAI\\'s DALL-E model\\n\\nText-to-image  generation\\n\\nhttps://python.langchain.com/docs/integrations/tools/dalle_image_generator\\n\\n\\nDataForSEO\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nSEO  data and analytics platform\\n\\nSEO  data, analytics\\n\\nhttps://python.langchain.com/docs/integrations/tools/dataforseo\\n\\n\\nDuckDuckGo  Search\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nPrivacy-focused  search engine\\n\\nSearch  engine\\n\\nhttps://python.langchain.com/docs/integrations/tools/ddg', metadata={'source': 'https://en.wikipedia.org/wiki/LangChain', 'title': 'LangChain - Wikipedia', 'language': 'en'}),\n",
              " Document(page_content='DuckDuckGo  Search\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nPrivacy-focused  search engine\\n\\nSearch  engine\\n\\nhttps://python.langchain.com/docs/integrations/tools/ddg\\n\\n\\nE2B  Data Analysis\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nSandbox  environment for running Python code for data analysis\\n\\nData  analysis environment\\n\\nhttps://python.langchain.com/docs/integrations/tools/e2b_data_analysis\\n\\n\\nEden  AI\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nSuite  of AI tools and APIs\\n\\nAI  tools, APIs\\n\\nhttps://python.langchain.com/docs/integrations/tools/edenai_tools\\n\\n\\nEleven  Labs Text2Speech\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nText-to-speech  API by Eleven Labs\\n\\nText-to-speech\\n\\nhttps://python.langchain.com/docs/integrations/tools/eleven_labs_tts\\n\\n\\nExa  Search\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nSearch  engine\\n\\nSearch  engine access\\n\\nhttps://python.langchain.com/docs/integrations/tools/exa_search\\n\\n\\nFile  System\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nTools  for interacting with the local file system\\n\\nFile  system interaction\\n\\nhttps://python.langchain.com/docs/integrations/tools/filesystem\\n\\n\\nGolden  Query\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nNatural  language APIs for querying various services\\n\\nNatural  language queries\\n\\nhttps://python.langchain.com/docs/integrations/tools/golden_query\\n\\n\\nGoogle  Cloud Text-to-Speech\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nText-to-speech  API by Google Cloud\\n\\nText-to-speech\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_cloud_texttospeech\\n\\n\\nGoogle  Drive\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nAccess  and manage files on Google Drive\\n\\nGoogle  Drive access\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_drive\\n\\n\\nGoogle  Finance\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nAccess  financial data from Google Finance\\n\\nFinancial  data\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_finance\\n\\n\\nGoogle  Jobs\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nSearch  for job listings using Google Jobs API\\n\\nJob  search\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_jobs\\n\\n\\nGoogle  Lens\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nVisual  search and recognition tool by Google\\n\\nVisual  search, recognition\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_lens\\n\\n\\nGoogle  Places\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nAccess  to Google Places API for location-based services\\n\\nLocation-based  services\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_places\\n\\n\\nGoogle  Scholar\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nSearch  for scholarly articles using Google Scholar API\\n\\nScholarly  article search\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_scholar\\n\\n\\nGoogle  Search\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nSearch  engine powered by Google\\n\\nSearch  engine\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_search\\n\\n\\nGoogle  Serper\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nSearch  engine results page (SERP) scraping tool\\n\\nSERP  scraping\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_serper\\n\\n\\nGoogle  Trends\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nAccess  to Google Trends data\\n\\nTrend  data\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_trends\\n\\n\\nGradio\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nLibrary  for creating UIs for machine learning models\\n\\nMachine  learning UIs\\n\\nhttps://python.langchain.com/docs/integrations/tools/gradio_tools\\n\\n\\nGraphQL\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nQuery  language for APIs\\n\\nAPI  queries\\n\\nhttps://python.langchain.com/docs/integrations/tools/graphql\\n\\n\\nHuggingFace  Hub\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nTools  for working with Hugging Face models and datasets\\n\\nHugging  Face models, datasets\\n\\nhttps://python.langchain.com/docs/integrations/tools/huggingface_tools\\n\\n\\nHuman  as a tool\\n\\nNo\\n\\nNo\\n\\nN/A\\n\\nUse  human input as a tool for AI\\n\\nHuman  input\\n\\nhttps://python.langchain.com/docs/integrations/tools/human_tools\\n\\n\\nIFTTT  WebHooks\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nConnect  and automate various web services\\n\\nWeb  service automation\\n\\nhttps://python.langchain.com/docs/integrations/tools/ifttt\\n\\n\\nIonic  Shopping\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nTool  for shopping using the Ionic API\\n\\nShopping\\n\\nhttps://python.langchain.com/docs/integrations/tools/ionic_shopping\\n\\n\\nLemon  Agent\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nTool  for interacting with the Lemon AI platform', metadata={'source': 'https://en.wikipedia.org/wiki/LangChain', 'title': 'LangChain - Wikipedia', 'language': 'en'}),\n",
              " Document(page_content='Shopping\\n\\nhttps://python.langchain.com/docs/integrations/tools/ionic_shopping\\n\\n\\nLemon  Agent\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nTool  for interacting with the Lemon AI platform\\n\\nLemon  AI interaction\\n\\nhttps://python.langchain.com/docs/integrations/tools/lemonai\\n\\n\\nMemorize\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nTool  for memorizing information using unsupervised learning\\n\\nMemorization\\n\\nhttps://python.langchain.com/docs/integrations/tools/memorize\\n\\n\\nNuclia\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nUnderstanding  Tool for indexing unstructured data using Nuclia\\n\\nData  indexing\\n\\nhttps://python.langchain.com/docs/integrations/tools/nuclia\\n\\n\\nOpenWeatherMap\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nAccess  to weather data using OpenWeatherMap API\\n\\nWeather  data\\n\\nhttps://python.langchain.com/docs/integrations/tools/openweathermap\\n\\n\\nPolygon  Stock Market API\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nAccess  to stock market data using Polygon API\\n\\nStock  market data\\n\\nhttps://python.langchain.com/docs/integrations/tools/polygon\\n\\n\\nPubMed\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nAccess  to biomedical literature using PubMed API\\n\\nBiomedical  literature\\n\\nhttps://python.langchain.com/docs/integrations/tools/pubmed\\n\\n\\nPython  REPL\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nInteractive  Python shell\\n\\nPython  shell\\n\\nhttps://python.langchain.com/docs/integrations/tools/python\\n\\n\\nReddit Search\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nSearch  for content on Reddit\\n\\nReddit  search\\n\\nhttps://python.langchain.com/docs/integrations/tools/reddit_search\\n\\n\\nRequests\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nHTTP  library for making requests\\n\\nHTTP  requests\\n\\nhttps://python.langchain.com/docs/integrations/tools/requests\\n\\n\\nSceneXplain\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nTool  for explaining the predictions of machine learning models\\n\\nModel  explanations\\n\\nhttps://python.langchain.com/docs/integrations/tools/sceneXplain\\n\\n\\nSearch\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nCollection  of tools for searching and querying various services\\n\\nSearch  tools\\n\\nhttps://python.langchain.com/docs/integrations/tools/search_tools\\n\\n\\nSearchApi\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nTool  for searching and querying various APIs\\n\\nAPI  search tools\\n\\nhttps://python.langchain.com/docs/integrations/tools/searchapi\\n\\n\\nSearxNG\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nSearch  Privacy-focused metasearch engine\\n\\nPrivacy-focused  search\\n\\nhttps://python.langchain.com/docs/integrations/tools/searx_search\\n\\n\\nSemantic  Scholar API\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\ntool  Access to academic papers using the Semantic Scholar API\\n\\nAcademic  paper search\\n\\nhttps://python.langchain.com/docs/integrations/tools/semanticscholar\\n\\n\\nSerpAPI\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nSearch  engine results page (SERP) scraping tool\\n\\nSERP  scraping\\n\\nhttps://python.langchain.com/docs/integrations/tools/serpapi\\n\\n\\nStackExchange\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nAccess  to the Stack Exchange network\\n\\nStack  Exchange access\\n\\nhttps://python.langchain.com/docs/integrations/tools/stackexchange\\n\\n\\nTavily  Search\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nSearch  engine for finding answers to questions\\n\\nQuestion  answering\\n\\nhttps://python.langchain.com/docs/integrations/tools/tavily_search\\n\\n\\nTwilio\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nCommunication  APIs for SMS, voice, and video\\n\\nCommunication  APIs\\n\\nhttps://python.langchain.com/docs/integrations/tools/twilio\\n\\n\\nWikidata\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nAccess  to structured data from Wikidata\\n\\nStructured  data access\\n\\nhttps://python.langchain.com/docs/integrations/tools/wikidata\\n\\n\\nWikipedia\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nAccess  to articles and information from Wikipedia\\n\\nWikipedia  access\\n\\nhttps://python.langchain.com/docs/integrations/tools/wikipedia\\n\\n\\nWolfram  Alpha\\n\\nNo\\n\\nYes\\n\\nProprietary\\n\\nComputational  knowledge engine\\n\\nComputational  knowledge\\n\\nhttps://python.langchain.com/docs/integrations/tools/wolfram_alpha\\n\\n\\nYahoo  Finance News\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nAccess  to financial news using Yahoo Finance API\\n\\nFinancial  news\\n\\nhttps://python.langchain.com/docs/integrations/tools/yahoo_finance_news\\n\\n\\nYoutube\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nAccess  to YouTube data and functionality\\n\\nYouTube  access\\n\\nhttps://python.langchain.com/docs/integrations/tools/youtube\\n\\n\\nZapier  Natural Language Actions\\n\\nNo\\n\\nYes', metadata={'source': 'https://en.wikipedia.org/wiki/LangChain', 'title': 'LangChain - Wikipedia', 'language': 'en'}),\n",
              " Document(page_content='Youtube\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nAccess  to YouTube data and functionality\\n\\nYouTube  access\\n\\nhttps://python.langchain.com/docs/integrations/tools/youtube\\n\\n\\nZapier  Natural Language Actions\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nIntegration  platform for automating workflows\\n\\nWorkflow  automation\\n\\nhttps://python.langchain.com/docs/integrations/tools/zapier\\n\\n\\n\\nReferences[edit]\\n\\n\\n^ \"Release 0.1.1\". 16 January 2024. Retrieved 19 January 2024.\\n\\n^ Buniatyan, Davit (2023). \"Code Understanding Using LangChain\". Activeloop.\\n\\n^ Auffarth, Ben (2023). Generative AI with LangChain. Birmingham: Packt Publishing. p.\\xa083. ISBN\\xa09781835083468.\\n\\n^ Palazzolo, Stephanie (2023-04-13). \"AI startup LangChain taps Sequoia to lead funding round at a valuation of at least $200 million\". Business Insider. Archived from the original on 2023-04-18. Retrieved 2023-04-18.\\n\\n^ Griffith, Erin; Metz, Cade (2023-03-14). \"\\'Let 1,000 Flowers Bloom\\': A.I. Funding Frenzy Escalates\". The New York Times. ISSN\\xa00362-4331. Archived from the original on 2023-04-18. Retrieved 2023-04-18.\\n\\n^ \"Introducing LangServe, the best way to deploy your LangChains\". LangChain Blog. 2023-10-12. Retrieved 2023-10-17.\\n\\n^ \"Chatbots | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain\". python.langchain.com. Retrieved 2023-11-26.\\n\\n^ \"Retrieval-augmented generation (RAG) | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain\". python.langchain.com. Retrieved 2023-11-26.\\n\\n^ \"Summarization | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain\". python.langchain.com. Retrieved 2023-11-26.\\n\\n^ \"Synthetic data generation | \\uf8ffü¶úÔ∏è\\uf8ffüîó Langchain\". python.langchain.com. Retrieved 2023-11-26.\\n\\n^ \"Milvus ‚Äî LangChain\". python.langchain.com. Retrieved 2023-10-29.\\n\\n^ \"Weaviate\". python.langchain.com. Retrieved 2024-01-17.\\n\\n^ Hug, Daniel Patrick (2023-03-08). \"Hierarchical topic tree of LangChain\\'s integrations\" (PDF). GitHub. Archived from the original on 2023-04-29. Retrieved 2023-04-18.\\n\\n^ \"Document Loaders ‚Äî LangChain 0.0.142\". python.langchain.com. Archived from the original on 2023-04-18. Retrieved 2023-04-18.\\n\\n\\nExternal links[edit]\\n\\n\\n\\nWikidata has data related to LangChain\\n\\nOfficial website\\nDiscord server support hub\\nvteOpenAIProducts\\nChatGPT\\nin education\\nDALL-E\\nGitHub Copilot\\nOpenAI Five\\nSora\\nWhisper\\nFoundation models\\nOpenAI Codex\\nGenerative pre-trained transformer\\nGPT-1\\nGPT-2\\nGPT-3\\nGPT-4\\nPeopleCEOs\\nSam Altman\\nremoval\\nMira Murati\\nEmmett Shear\\nBoard of directorsCurrent\\nBret Taylor\\nLarry Summers\\nAdam D\\'Angelo\\nFormer\\nGreg Brockman (2017‚Äì2023)\\nReid Hoffman (2019‚Äì2023)\\nWill Hurd (2021‚Äì2023)\\nHolden Karnofsky (2017‚Äì2021)\\nElon Musk (2015‚Äì2018)\\nIlya Sutskever (2017‚Äì2023)\\nHelen Toner (2021‚Äì2023)\\nShivon Zilis (2019‚Äì2023)\\nRelated\\nAI Dungeon\\nAuto-GPT\\n\"Deep Learning\"\\nLangChain\\nMicrosoft Copilot\\nMicrosoft Bing\\n\\n Category\\n Commons', metadata={'source': 'https://en.wikipedia.org/wiki/LangChain', 'title': 'LangChain - Wikipedia', 'language': 'en'}),\n",
              " Document(page_content='Category\\n Commons\\n\\nvteDifferentiable computingGeneral\\nDifferentiable programming\\nInformation geometry\\nStatistical manifold\\nAutomatic differentiation\\nNeuromorphic engineering\\nPattern recognition\\nTensor calculus\\nComputational learning theory\\nInductive bias\\nConcepts\\nGradient descent\\nSGD\\nClustering\\nRegression\\nOverfitting\\nHallucination\\nAdversary\\nAttention\\nConvolution\\nLoss functions\\nBackpropagation\\nBatchnorm\\nActivation\\nSoftmax\\nSigmoid\\nRectifier\\nRegularization\\nDatasets\\nAugmentation\\nDiffusion\\nAutoregression\\nApplications\\nMachine learning\\nIn-context learning\\nArtificial neural network\\nDeep learning\\nScientific computing\\nArtificial Intelligence\\nLanguage model\\nLarge language model\\nHardware\\nIPU\\nTPU\\nVPU\\nMemristor\\nSpiNNaker\\nSoftware libraries\\nTensorFlow\\nPyTorch\\nKeras\\nTheano\\nJAX\\nFlux.jl\\nMindSpore\\nImplementationsAudio‚Äìvisual\\nAlexNet\\nWaveNet\\nHuman image synthesis\\nHWR\\nOCR\\nSpeech synthesis\\nSpeech recognition\\nFacial recognition\\nAlphaFold\\nDALL-E\\nMidjourney\\nStable Diffusion\\nWhisper\\nVerbal\\nWord2vec\\nSeq2seq\\nBERT\\nGemini\\nLaMDA\\nBard\\nNMT\\nProject Debater\\nIBM Watson\\nIBM Watsonx\\nGranite\\nGPT-1\\nGPT-2\\nGPT-3\\nGPT-4\\nChatGPT\\nGPT-J\\nChinchilla AI\\nPaLM\\nBLOOM\\nLLaMA\\nPanGu-Œ£\\nDecisional\\nAlphaGo\\nAlphaZero\\nQ-learning\\nSARSA\\nOpenAI Five\\nSelf-driving car\\nMuZero\\nAction selection\\nAuto-GPT\\nRobot control\\nPeople\\nYoshua Bengio\\nAlex Graves\\nIan Goodfellow\\nStephen Grossberg\\nDemis Hassabis\\nGeoffrey Hinton\\nYann LeCun\\nFei-Fei Li\\nAndrew Ng\\nJ√ºrgen Schmidhuber\\nDavid Silver\\nIlya Sutskever\\nOrganizations\\nAnthropic\\nEleutherAI\\nGoogle DeepMind\\nHugging Face\\nOpenAI\\nMeta AI\\nMila\\nMIT CSAIL\\nHuawei\\nArchitectures\\nNeural Turing machine\\nDifferentiable neural computer\\nTransformer\\nRecurrent neural network (RNN)\\nLong short-term memory (LSTM)\\nGated recurrent unit (GRU)\\nEcho state network\\nMultilayer perceptron (MLP)\\nConvolutional neural network\\nResidual neural network\\nMamba\\nAutoencoder\\nVariational autoencoder (VAE)\\nGenerative adversarial network (GAN)\\nGraph neural network\\n\\n Portals\\nComputer programming\\nTechnology\\n Categories\\nArtificial neural networks\\nMachine learning\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=LangChain&oldid=1207691404\"\\nCategories: Artificial intelligenceLarge language modelsSoftware frameworks2022 softwareHidden categories: Articles with short descriptionShort description matches WikidataPages using Sister project links with hidden wikidata\\n\\n\\n\\n\\n\\n\\n This page was last edited on 15 February 2024, at 12:57\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike License 4.0;\\nadditional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia¬Æ is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle limited content width', metadata={'source': 'https://en.wikipedia.org/wiki/LangChain', 'title': 'LangChain - Wikipedia', 'language': 'en'})]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = FAISS.from_documents(documents, embeddings)"
      ],
      "metadata": {
        "id": "_AwiQ-S_8b3q"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create chain for documents\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "template = \"\"\"Answer the following question based only on the provided context:\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "<context>\n",
        "\n",
        "Question: {input}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "document_chain = create_stuff_documents_chain(llm, prompt)"
      ],
      "metadata": {
        "id": "i-uz85E-88A3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually passing a document\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_chain.invoke(\n",
        "    \"input\": \"What is langchain?\",\n",
        "    \"context\": \"\"\n",
        ")"
      ],
      "metadata": {
        "id": "xjdhew8h-BsM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}